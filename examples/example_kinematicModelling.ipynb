{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example of an application of the kinematic modelling to the open cluster IC2602 **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "from scipy import linalg\n",
    "import scipy.optimize as opt\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import wcs\n",
    "from astropy.coordinates import *\n",
    "from astropy import units as u\n",
    "import time\n",
    "\n",
    "\n",
    "from routines_mod import *\n",
    "from derivatives_mod import *\n",
    "from matrixOperations import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input file. In this case I am using the member list from van Leeuwen at al. (2017).\n",
    "Note that in the paper Bravi et al. (2018) we also used a sub-set of this membership list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hdu = fits.open('Data/vanLeeuwen/ic2602_all.fits')\n",
    "data2602 = hdu[1].data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### The code requires ra  and dec to be in radians.\n",
    "\n",
    "c = SkyCoord(ra = data2602['RA_ICRS']*u.degree, dec = data2602['DE_ICRS']*u.degree)\n",
    "alpha, delta = c.ra.radian, c.dec.radian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Number of stars\n",
    "N = len(data2602['RA_ICRS']) \n",
    "\n",
    "#### Observables arrays, errors, and correlation coefficients\n",
    "prlx, pmra, pmdec = data2602['Plx'], data2602['pmRA'], data2602['pmDE']\n",
    "e_prlx, e_pmra, e_pmdec = data2602['e_Plx'], data2602['e_pmRA'], data2602['e_pmDE']\n",
    "cc_prlx_pmra, cc_prlx_pmdec, cc_pmra_pmdec = data2602['PlxpmRAcor'], data2602['PlxpmDEcor'], data2602['pmRApmDEcor'] \n",
    "\n",
    "#### Define three matrixes, one for the observed quantities, \n",
    "#### one for the errors and one for the correlation coefficients\n",
    "\n",
    "obs = np.transpose(np.array([prlx,pmra,pmdec]))\n",
    "sigma = np.transpose(np.array([e_prlx, e_pmra, e_pmdec]))\n",
    "#cc = np.transpose(np.array([cc_prlx_pmra, cc_prlx_pmdec, cc_pmra_pmdec]))  \n",
    "\n",
    "cc = np.zeros((N, 3))\n",
    "\n",
    "cc[:,0] = cc_prlx_pmra \n",
    "cc[:,1] = cc_prlx_pmdec\n",
    "cc[:,2] = cc_pmra_pmdec\n",
    "\n",
    "\n",
    "#### Source Id \n",
    "gaiaid = data2602['Source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next comes possibly the **most important** part of the code, which is chosing the initial values \n",
    "for the minimization algorithm. \n",
    "The user needs to specify the initial values for the centre velocity, the velocity dispersion and \n",
    "the parallaxes.\n",
    "For the parallaxes it is easy, you start with the observed ones.\n",
    "For the velocity and the velocity dispersion you have to rely on your prior knowledge of the cluster.\n",
    "For example, if you have an idea of the average parallax, proper motion and radial velocity \n",
    "you can convert those into cartesian coordinates. \n",
    "**The final results depend in different (complex) ways on the initial parameters. **\n",
    "So if you're not sure the best way is to try with many  and then study the final parameter distribution.\n",
    "\n",
    "Usually for nearby clusters the proper motions and the parallax are large enough to allow a decent determination of the parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sigmav = 0.3 #### km/s\n",
    "vx, vy, vz = -9.55, 16.65, -12.54 ### km/s\n",
    "initial_guesses = np.concatenate((obs[:, 0],np.array([vx, vy, vz, sigmav])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First iteration**\n",
    "\n",
    "There are two parameters to specify: grad e method.\n",
    "\n",
    "You can decide whether to use or not the likelihood gradient in the minimization. If you want to use it \n",
    "write 'YES' and then in the method remember to specify a minimization method that actually requires the\n",
    "likelihood gradient to be specified (e.g. Newton-CG). Otherwise type 'NO' (method = 'Nelder-Mead' or 'Powell'). The Hessian of the likelihood is also available. I used it to compute errors on the estimated quantities (Cramer Rao inequality), however it is also possible to use it for the minimization. In this case type 'HESS' and then specify 'Newton-CG' as a method.\n",
    "\n",
    "For an overview of the minimization methods, you can have a look at: \n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example with Gradient **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -56.173386\n",
      "         Iterations: 11\n",
      "         Function evaluations: 34\n",
      "         Gradient evaluations: 181\n",
      "         Hessian evaluations: 0\n",
      "vx:  -9.97447616327 vy:  16.7720084299 vz:  -13.8312666216 sigma_v:  0.408290550096\n",
      "Max g value:  71.5564386277\n",
      "Total Time: 0.4 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "grad = 'YES' \n",
    "method = 'Newton-CG'\n",
    "\n",
    "result = optimizer(grad, method, initial_guesses, alpha, delta, \n",
    "                   obs, sigma, cc, N)\n",
    "g_fin = g_func(result, alpha, delta, obs, sigma, cc, N)\n",
    "g_fin_max = np.max(g_fin)\n",
    "\n",
    "print( 'vx: ',result[-4], 'vy: ',result[-3], 'vz: ', result[-2], 'sigma_v: ', result[-1])\n",
    "print( 'Max g value: ', g_fin_max)\n",
    "print( 'Total Time:', round(time.time()-t0, 2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Example without Gradient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: -61.284037\n",
      "         Iterations: 100557\n",
      "         Function evaluations: 111697\n",
      "vx:  -10.3648926981 vy:  16.9409711352 vz:  -14.6925608755 sigma_v:  0.480131381874\n",
      "Max g value:  51.8865027849\n",
      "Total Time: 73.73 s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "grad = 'NO' \n",
    "method = 'Nelder-Mead'\n",
    "\n",
    "result = optimizer(grad, method, initial_guesses, alpha, delta, \n",
    "                   obs, sigma, cc, N)\n",
    "g_fin = g_func(result, alpha, delta, obs, sigma, cc, N)\n",
    "g_fin_max = np.max(g_fin)\n",
    "\n",
    "print( 'vx: ',result[-4], 'vy: ',result[-3], 'vz: ', result[-2], 'sigma_v: ', result[-1])\n",
    "print( 'Max g value: ', g_fin_max)\n",
    "print( 'Total Time:', round(time.time()-t0, 2), 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the results after the first minimization are quite in agreement. \n",
    "The difference between the two methods consists - in this case - mainly in the execution time, which is much shorter \n",
    "using the gradient.\n",
    "\n",
    "The reason to use the Nelder-Mead method is that sometimes the Newton-CG iterations do not converge properly or they have problems with the required precision. Nelder-Mead does not give such problems.\n",
    "\n",
    "One way to deal with such convergence problems is to change the parameted 'xtol' in the function called 'optimizer' (see routines_mod.py).\n",
    "\n",
    "\n",
    "So **my opinion** is that one should always double-check with both methods and possibly without parallax minimization (see notebook) to check whether the values obtained are reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Further iterations **\n",
    "\n",
    "The variable $g$ is a measure of the quadratic difference between the observed and modelled quantities (i.e. parallaxes and proper motions), and it is nearly distributed as $\\chi^2_2$\n",
    "\n",
    "A $~1 \\% $ significance level correponds to $g \\sim 14$.\n",
    "In Bravi et al. (2018) we chose $g_{threshold} = 15$.\n",
    "\n",
    "Therefore stars with a value of $g > g_{threshold}$ are excluded one by one, and the parameters computed again for the new set of observables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New N value:  65\n",
      "GaiaID of excluded star:  [5252084918078077952]\n",
      "Warning: CG iterations didn't converge.  The Hessian is not positive definite.\n",
      "         Current function value: -71.579090\n",
      "         Iterations: 3\n",
      "         Function evaluations: 4\n",
      "         Gradient evaluations: 2781\n",
      "         Hessian evaluations: 0\n",
      "Max g value:  20.339403888\n",
      " Likelihood:  -71.57908968602385\n",
      "vx: -9.57 km/s,  vy: 16.52 km/s,  vz: -12.55 km/s,  sigma_v: 0.34 km/s, \n",
      "e_vx: 0.74 km/s,  e_vy:  0.3 km/s,  e_vz: 1.65 km/s,  e_sigmav:  0.03 km/s \n",
      "New N value:  64\n",
      "GaiaID of excluded star:  [5239689092704584704]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -142.266390\n",
      "         Iterations: 8\n",
      "         Function evaluations: 36\n",
      "         Gradient evaluations: 2236\n",
      "         Hessian evaluations: 0\n",
      "Max g value:  22.7587702687\n",
      " Likelihood:  -142.26638951693312\n",
      "vx: -10.67 km/s,  vy: 16.95 km/s,  vz: -15.18 km/s,  sigma_v: 0.15 km/s, \n",
      "e_vx: 0.44 km/s,  e_vy:  0.2 km/s,  e_vz: 0.98 km/s,  e_sigmav:  0.02 km/s \n",
      "New N value:  63\n",
      "GaiaID of excluded star:  [5251495957802232448]\n",
      "Warning: Desired error not necessarily achieved due to precision loss.\n",
      "         Current function value: -157.601996\n",
      "         Iterations: 10\n",
      "         Function evaluations: 34\n",
      "         Gradient evaluations: 300\n",
      "         Hessian evaluations: 0\n",
      "Max g value:  21.5448365696\n",
      " Likelihood:  -157.60199642297337\n",
      "vx: -11.02 km/s,  vy: 17.09 km/s,  vz: -16.0 km/s,  sigma_v: 0.13 km/s, \n",
      "e_vx: 0.41 km/s,  e_vy:  0.19 km/s,  e_vz: 0.93 km/s,  e_sigmav:  0.02 km/s \n",
      "New N value:  62\n",
      "GaiaID of excluded star:  [5241458584871666176]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -176.879175\n",
      "         Iterations: 12\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 316\n",
      "         Hessian evaluations: 0\n",
      "Max g value:  20.291855965\n",
      " Likelihood:  -176.87917519977327\n",
      "vx: -10.96 km/s,  vy: 17.06 km/s,  vz: -15.87 km/s,  sigma_v: 0.14 km/s, \n",
      "e_vx: 0.42 km/s,  e_vy:  0.19 km/s,  e_vz: 0.94 km/s,  e_sigmav:  0.02 km/s \n",
      "New N value:  61\n",
      "GaiaID of excluded star:  [5237036555261723648]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -180.851457\n",
      "         Iterations: 11\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 172\n",
      "         Hessian evaluations: 0\n",
      "Max g value:  18.9285689874\n",
      " Likelihood:  -180.8514569273467\n",
      "vx: -10.81 km/s,  vy: 16.96 km/s,  vz: -15.49 km/s,  sigma_v: 0.12 km/s, \n",
      "e_vx: 0.38 km/s,  e_vy:  0.18 km/s,  e_vz: 0.85 km/s,  e_sigmav:  0.01 km/s \n",
      "New N value:  60\n",
      "GaiaID of excluded star:  [5245507295921159680]\n",
      "Optimization terminated successfully.\n",
      "         Current function value: -204.563208\n",
      "         Iterations: 14\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 312\n",
      "         Hessian evaluations: 0\n",
      "Max g value:  12.9163053016\n",
      " Likelihood:  -204.56320812642295\n",
      "vx: -11.69 km/s,  vy: 17.31 km/s,  vz: -17.45 km/s,  sigma_v: 0.12 km/s, \n",
      "e_vx: 0.39 km/s,  e_vy:  0.19 km/s,  e_vz: 0.87 km/s,  e_sigmav:  0.01 km/s \n"
     ]
    }
   ],
   "source": [
    "g_lim = 15.\n",
    "while (g_fin_max > g_lim):\n",
    "    N_survive = len(g_fin[g_fin < g_fin_max])\n",
    "    print( 'New N value: ', N_survive)\n",
    "\n",
    "    alpha_sel, delta_sel = np.zeros(N_survive), np.zeros(N_survive)\n",
    "    obs_sel = np.zeros((N_survive, 3))\n",
    "    sigma_sel = np.zeros((N_survive, 3))\n",
    "    cc_sel =  np.zeros((N_survive, 3))\n",
    "    gaiaId_sel = np.zeros(N_survive)\n",
    "\n",
    "\n",
    "    alpha_sel, delta_sel = alpha[g_fin < g_fin_max], delta[g_fin < g_fin_max]\n",
    "    obs_sel[:, 0], obs_sel[:, 1], obs_sel[:, 2] = obs[g_fin < g_fin_max,0], obs[g_fin < g_fin_max,1], \\\n",
    "                                                  obs[g_fin < g_fin_max,2]\n",
    "    sigma_sel[:, 0], sigma_sel[:, 1], sigma_sel[:, 2] = sigma[g_fin < g_fin_max,0], \\\n",
    "                                                        sigma[g_fin < g_fin_max,1], sigma[g_fin < g_fin_max,2]\n",
    "    cc_sel[:, 0], cc_sel[:, 1], cc_sel[:, 2] = cc[g_fin < g_fin_max,0], cc[g_fin < g_fin_max,1], \\\n",
    "                                               cc[g_fin < g_fin_max,2] \n",
    "    gaiaId_sel = gaiaid[g_fin < g_fin_max]\n",
    "\n",
    "\n",
    "    print( 'GaiaID of excluded star: ', gaiaid[(g_fin >= g_fin_max)])\n",
    "    \n",
    "    \n",
    "    N = N_survive\n",
    "    init_par_sel =  np.concatenate((obs_sel[:, 0], np.array([vx, vy, vz, sigmav])))\n",
    "    result_sel = optimizer(grad, method, init_par_sel, \n",
    "                           alpha_sel, delta_sel, obs_sel,  sigma_sel,cc_sel, N)\n",
    "    g_fin = g_func(result_sel, alpha_sel, delta_sel, \n",
    "                   obs_sel, \n",
    "                   sigma_sel,cc_sel, N)\n",
    "    g_fin_max = np.max(g_fin)\n",
    "\n",
    "\n",
    "    ### Compute errors on quantities.\n",
    "    H =  -Nmatrix(result_sel, alpha_sel, delta_sel,obs_sel, sigma_sel,cc_sel, N)\n",
    "    invH =  linalg.inv(H)\n",
    "    err = np.zeros(N+4)\n",
    "    for i in range(N+4):\n",
    "        err[i] = np.sqrt(-invH[i,i])\n",
    "\n",
    "    ### Upload initial values\n",
    "    alpha, delta = alpha_sel,delta_sel\n",
    "    obs, sigma, cc = obs_sel, sigma_sel, cc_sel\n",
    "    gaiaid = gaiaId_sel\n",
    "\n",
    "\n",
    "    ### Print\n",
    "    U =  Ulike(result_sel,  alpha_sel, delta_sel, obs_sel, sigma_sel, cc_sel, N)\n",
    "    print('Max g value: ', g_fin_max)\n",
    "    print( ' Likelihood: ', U)\n",
    "    print( 'vx:',round(result_sel[-4],2),'km/s, ', 'vy:',round(result_sel[-3],2),'km/s, ', \n",
    "          'vz:', round(result_sel[-2],2),'km/s, ', 'sigma_v:',round( result_sel[-1],2), 'km/s, ',)\n",
    "    print('e_vx:', round(err[-4], 2),'km/s, ', 'e_vy: ', round(err[-3], 2),'km/s, ', \n",
    "          'e_vz:', round(err[-2],2),'km/s, ', 'e_sigmav: ', round(err[-1],2), 'km/s ')\n",
    "    \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final parameters using Nelder-Mead:**\n",
    "\n",
    "$v_x = -11.72  \\pm 0.53 $ km/s\n",
    "\n",
    "$v_y = 17.31 \\pm  0.23  $ km/s\n",
    "\n",
    "$v_z = -17.53 \\pm  1.18  $ km/s\n",
    "\n",
    "$\\sigma_v= 0.2 \\pm   0.02 $ km/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Final parameters from Newton-CG: **\n",
    "\n",
    "\n",
    "$v_x = -11.69  \\pm 0.62 $ km/s\n",
    "\n",
    "$v_y = 17.31 \\pm  0.26  $ km/s\n",
    "\n",
    "$v_z = -17.45 \\pm  1.38  $ km/s\n",
    "\n",
    "$\\sigma_v= 0.12 \\pm   0.01 $ km/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Remarks**\n",
    "\n",
    "The estimated parameters are compatible. With Newton-CG there are some warnings related to precision/convergence loss. So my suggestion is to always double - check with the two methods the parameters obtained (and possibly also with other methods, see e.g. this notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last step - unbiased velocity dispersion**\n",
    "\n",
    "Now the velocity dispersion obtained with this method is underestimated. Therefore we use the formulae in \n",
    "Lindegren et al. (2000) appendix A.4 to compute a better value for $\\sigma_v$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velocity dispersion: [ 0.25] km/s\n",
      "Error on velocity dispersion: [ 0.02] km/s\n"
     ]
    }
   ],
   "source": [
    "_A = auKmYearPerSec\n",
    "v = [result_sel[-4], result_sel[-3], result_sel[-2]]  ### These are vx, vy, vz\n",
    "prlx_est = result_sel[:-4] ### Estimated parallaxes\n",
    "\n",
    "\n",
    "p, q, r = normalTriad(alpha_sel, delta_sel) ### Remember that coordinates must be in radians.\n",
    "pmra_est = np.dot(np.transpose(p),v)*prlx_est/_A\n",
    "pmde_est = np.dot(np.transpose(q),v)*prlx_est/_A\n",
    "\n",
    "#### Observed quantities\n",
    "prlx, pmra, pmdec = obs_sel[:,0], obs_sel[:,1], obs_sel[:,2]  \n",
    "\n",
    "\n",
    "### Define new coordinate system, as in appendix A.4 of Lindegren+00\n",
    "N = len(alpha_sel)\n",
    "k_perp = []\n",
    "\n",
    "for i in range(N): \n",
    "    k_perp_ = np.cross(r.T[i], v)\n",
    "    k_perp_ = k_perp_/(k_perp_[0]**2.+k_perp_[1]**2.+k_perp_[2]**2.)**(0.5) ### Eq. A.19\n",
    "    k_perp.append(k_perp_)\n",
    "\n",
    "k_par = []\n",
    "\n",
    "for i in range(N):\n",
    "    k_par_ = np.cross(r.T[i], k_perp[i])  ### Eq. A.19\n",
    "    k_par.append(k_par_)\n",
    "    \n",
    "h = []\n",
    "for i in range(N):\n",
    "    h_ = np.dot(np.asarray([np.zeros(3), p.T[i], q.T[i]]), k_perp[i])   ### Eq. A.20\n",
    "    h.append(h_)\n",
    "    \n",
    "eta = []\n",
    "\n",
    "for i in range(N):\n",
    "    eta_ = np.dot(h[i], [prlx[i] - prlx_est[i],\n",
    "                         pmra[i] - pmra_est[i], \n",
    "                         pmdec[i] - pmde_est[i]])   \n",
    "    eta_ = eta_*_A/prlx_est[i]  ### Eq. A.21\n",
    "    eta.append(eta_)\n",
    "    \n",
    "\n",
    "\n",
    "### In this covariance matrix only the proper motion errors are taken into account\n",
    "C = np.zeros((3,3,N),dtype=np.float64)\n",
    "C[0, 0, :] = np.zeros(N)\n",
    "C[1,1,:] = (sigma_sel[:, 1])**2.\n",
    "C[2,2,:] = (sigma_sel[:, 2])**2.\n",
    "plxPmRa, plxPmDec, pmRapmDec = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "pmRapmDec =  cc_sel[:, 2] \n",
    "C[0,1,:], C[0,2,:] =plxPmRa*sigma_sel[:, 0]*sigma_sel[:, 1], plxPmDec*sigma_sel[:, 0]*sigma_sel[:, 2]\n",
    "C[1,0,:], C[1,2,:] = plxPmRa*sigma_sel[:, 0]*sigma_sel[:, 1], pmRapmDec*sigma_sel[:, 1]*sigma_sel[:, 2]\n",
    "C[2,0,:], C[2,1,:] = plxPmDec*sigma_sel[:, 0]*sigma_sel[:, 2], pmRapmDec*sigma_sel[:, 1]*sigma_sel[:, 2]\n",
    "\n",
    "\n",
    "sigma_eta = []\n",
    "for i in range(N):\n",
    "    sigma_eta_ = np.dot(np.dot(h[i],C[:,:,i]), h[i])\n",
    "    sigma_eta_ = _A*(sigma_eta_)**0.5/prlx_est[i]  ### Eq. A.22\n",
    "    sigma_eta.append(sigma_eta_)\n",
    "    \n",
    "\n",
    "### Compute the dispersion perpendicular to the radial velocity direction\n",
    "### The function is described in Eq. A. 23\n",
    "def func(observations, x):\n",
    "    e, sigma_e = observations\n",
    "    f = np.zeros(N)\n",
    "    f[:] = (e**2. - x**2 - sigma_e**2.)/(x**2. + sigma_e**2.)**2.\n",
    "    return np.sum(f)\n",
    "\n",
    "sigma_perp, cov = opt.curve_fit(func, np.array([eta, sigma_eta]), np.zeros(N), p0 = 0.3, maxfev = 2000)\n",
    "sigma_perp_err_ = (np.asarray(sigma_perp)**2.+ np.asarray(sigma_eta)**2)**(-2.)\n",
    "sigma_perp_err = (2*np.abs(sigma_perp)*np.sum(sigma_perp_err_))**(-0.5) ### Eq. A.24\n",
    "\n",
    "print('Velocity dispersion:', np.round(sigma_perp, 2), 'km/s')\n",
    "print('Error on velocity dispersion:', np.round(sigma_perp_err, 2), 'km/s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
